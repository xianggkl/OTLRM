{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xmwang/programs/miniconda3/envs/imagefusion-LRRNet/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from turtle import forward\n",
    "import torch\n",
    "from torch import nn, optim \n",
    "from torch.autograd import Variable \n",
    "import os \n",
    "from utils import * \n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import numpy as np \n",
    "import scipy.io as scio\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io\n",
    "import math\n",
    "import time\n",
    "from math import exp\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "data = ['MSI_pompoms']\n",
    "Sample_folder = ['0.05']\n",
    "base = [35]\n",
    "\n",
    "# tune for best performance\n",
    "shrink = [7]\n",
    "c_all = [2e-8]\n",
    "\n",
    "max_iter = 6000\n",
    "lr_real = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def torch_psnr(img, ref):  # input [28,256,256]\n",
    "    img = (img*256).round()\n",
    "    ref = (ref*256).round()\n",
    "    nC = img.shape[0]\n",
    "    psnr = 0\n",
    "    for i in range(nC):\n",
    "        mse = torch.mean((img[i, :, :] - ref[i, :, :]) ** 2)\n",
    "        psnr += 10 * torch.log10((255*255)/mse)\n",
    "    return psnr / nC\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
    "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "def ssim(img1, img2, window_size=11, size_average=True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "\n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "\n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
    "\n",
    "def torch_ssim(img, ref):  # input [28,256,256]\n",
    "    return ssim(torch.unsqueeze(img, 0), torch.unsqueeze(ref, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diagonal_S_1(nn.Module):\n",
    "    def __init__(self, n1,n2,n3):\n",
    "        super(diagonal_S_1, self).__init__()\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "        self.n3 = n3\n",
    "    \n",
    "    def forward(self, s):\n",
    "        tensor = torch.zeros(self.n3, self.n1, self.n2).cuda()\n",
    "        for i in range(self.n3):\n",
    "            tensor[i] = torch.diag(s[i])\n",
    "        return tensor\n",
    "\n",
    "class OTLinear_new(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.n_dim = shape\n",
    "        self.num_householders = shape\n",
    "        self.u = nn.Parameter(torch.randn(self.num_householders, self.n_dim))\n",
    "        self.I = nn.Parameter(torch.eye(self.n_dim, self.n_dim).unsqueeze(0))\n",
    "        self.I.requires_grad = False\n",
    "    \n",
    "    def get_weight(self, ):\n",
    "        u = F.normalize(self.u, dim=1)\n",
    "        w = self.I - 2 * u.unsqueeze(-1) @ u.unsqueeze(1)\n",
    "        w = torch.chain_matmul(*[x.squeeze(0) for x in w.chunk(self.num_householders, dim=0)])\n",
    "        return w\n",
    "        \n",
    "    def forward(self):\n",
    "        return self.get_weight()\n",
    "    \n",
    "class orth_linear(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.n_dim = shape\n",
    "        self.num_householders = shape\n",
    "        self.u = nn.Parameter(torch.randn(self.num_householders, self.n_dim))\n",
    "        self.I = nn.Parameter(torch.eye(self.n_dim, self.n_dim).unsqueeze(0))\n",
    "        self.I.requires_grad = False\n",
    "\n",
    "    def get_weight(self, ):\n",
    "        u = F.normalize(self.u, dim=1)\n",
    "        w = self.I - 2 * u.unsqueeze(-1) @ u.unsqueeze(1)\n",
    "        w = torch.chain_matmul(*[x.squeeze(0) for x in w.chunk(self.num_householders, dim=0)])\n",
    "        return w\n",
    "    \n",
    "    def forward(self, input):\n",
    "        weight = self.get_weight()\n",
    "        return torch.nn.functional.linear(input, weight)\n",
    "\n",
    "\n",
    "class SVD_net(nn.Module): \n",
    "    def __init__(self,n_1,n_2,n_3,shrink,shape):\n",
    "        super(SVD_net, self).__init__()\n",
    "        # shrink = 25\n",
    "        self.shape = shape\n",
    "        self.A = nn.Parameter(torch.Tensor(n_1,n_2//shrink,n_3))\n",
    "        self.s = nn.Parameter(torch.Tensor(n_2//shrink,n_3))\n",
    "        self.B = nn.Parameter(torch.Tensor(n_2,n_2//shrink,n_3))\n",
    "        \n",
    "        self.net_t = nn.Sequential(\n",
    "            permute_change(1,2,0),\n",
    "            orth_linear(n_3),\n",
    "            nn.Linear(n_3, n_3, bias=False)\n",
    "        ) \n",
    "        self.reset_parameters()\n",
    "        \n",
    "        self.netA = nn.Sequential(\n",
    "            orth_linear(n_3),\n",
    "            permute_change(2,0,1)\n",
    "        )\n",
    "        self.netB = nn.Sequential(\n",
    "            orth_linear(n_3),\n",
    "            permute_change(2,0,1)\n",
    "        )\n",
    "        \n",
    "        self.diagnet = diagonal_S_1(n_2//shrink, n_2//shrink, n_3)\n",
    "        self.adaptive_thres_net = nn.Sequential(\n",
    "            nn.Linear(n_2//shrink,n_2//shrink,bias = False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(n_2//shrink,n_2//shrink,bias = False)\n",
    "        )\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.A.size(2))\n",
    "        self.A.data.uniform_(-stdv, stdv)\n",
    "        self.B.data.uniform_(-stdv, stdv)\n",
    "        self.s.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self):\n",
    "        A_hat = self.netA(self.A)\n",
    "        B_hat_T = (self.netB(self.B)).permute(0,2,1)\n",
    "        x = torch.matmul(torch.matmul(A_hat,self.diagnet(self.adaptive_thres_net( (self.s).t() ))), B_hat_T)\n",
    "        return self.net_t(x), A_hat, B_hat_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 581827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xmwang/programs/miniconda3/envs/imagefusion-LRRNet/lib/python3.7/site-packages/torch/functional.py:1638: UserWarning: torch.chain_matmul is deprecated and will be removed in a future PyTorch release. Use torch.linalg.multi_dot instead, which accepts a list of two or more tensors rather than multiple parameters. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/aten/src/ATen/native/LinearAlgebra.cpp:877.)\n",
      "  return _VF.chain_matmul(matrices)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:249,psnr:29.510841369628906\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:499,psnr:33.15288543701172\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:749,psnr:34.04817199707031\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:999,psnr:34.552555084228516\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:1249,psnr:34.864925384521484\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:1499,psnr:34.956581115722656\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:1749,psnr:35.107242584228516\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:1999,psnr:35.14347457885742\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:2249,psnr:35.166072845458984\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:2499,psnr:35.07475280761719\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:2749,psnr:35.24803924560547\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:2999,psnr:35.282745361328125\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:3249,psnr:35.29722213745117\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:3499,psnr:35.28346252441406\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:3749,psnr:35.31519317626953\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:3999,psnr:35.283241271972656\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:4249,psnr:35.23249816894531\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:4499,psnr:33.61091995239258\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:4749,psnr:34.948204040527344\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:4999,psnr:35.19755935668945\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:5249,psnr:35.32422637939453\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:5499,psnr:35.43204879760742\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:5749,psnr:35.501075744628906\n",
      "\n",
      "data:MSI_pompomssr:0.05r:7,gamma:2e-08,iter:5999,psnr:35.52776336669922\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur = -1\n",
    "for cur_data in data:\n",
    "    folder_path = \"./results/tensor_completion/ours/\" + cur_data + \"/\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "            \n",
    "    for cur_sr in Sample_folder:\n",
    "        cur = cur + 1\n",
    "        # file_name = './data/tensor_completion/video_data/' + cur_data + '/' + cur_sr + '/' + 'video_' + cur_data + '.mat'\n",
    "        file_name = './data/tensor_completion/MSI_data/' + cur_data + '/' + cur_sr + '/' + cur_data + '.mat'\n",
    "\n",
    "        mat = scipy.io.loadmat(file_name)\n",
    "        X_np = mat[\"img_sr\"]\n",
    "        X = torch.from_numpy(X_np).type(dtype).cuda()\n",
    "        truth = torch.from_numpy(mat[\"tensor\"]).type(dtype).cuda()\n",
    "        \n",
    "        folder_path = \"./results/tensor_completion/ours/\" + cur_data + \"/\" + cur_sr + \"/\"\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.mkdir(folder_path)\n",
    "            \n",
    "        for r in shrink:\n",
    "            folder_path = \"./results/tensor_completion/ours/\" + cur_data + \"/\" + cur_sr + \"/\" + \"r\" + str(r) + \"/\"\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.mkdir(folder_path)\n",
    "            \n",
    "            for gamma in c_all:\n",
    "                folder_path = \"./results/tensor_completion/ours/\" + cur_data + \"/\" + cur_sr + \"/\" + \"r\" + str(r) + \"/\" + \"gamma\" + str(gamma) + \"/\"\n",
    "                if not os.path.exists(folder_path):\n",
    "                    os.mkdir(folder_path)\n",
    "                \n",
    "                F_norm = nn.MSELoss()\n",
    "                \n",
    "                # model = SVD_net(288,352,30, r,256).type(dtype) # video\n",
    "                model = SVD_net(256,256,31, r,256).type(dtype) # MSI\n",
    "                mask = torch.ones(X.shape).type(dtype)\n",
    "                mask[X == 0] = 0\n",
    "                X[mask == 0] = 0\n",
    "                \n",
    "                params = []\n",
    "                params += [x for x in model.parameters()]\n",
    "                \n",
    "                s = sum([np.prod(list(p.size())) for p in params]);\n",
    "                print('Number of params: %d' % s)\n",
    "                optimizier = optim.Adam(params, lr=lr_real, weight_decay=10e-8)\n",
    "                \n",
    "                for iter in range(max_iter):\n",
    "                    X_Out_real, A_hat, B_hat = model()\n",
    "\n",
    "                    loss_f = 0\n",
    "                    loss_A = 0\n",
    "                    loss_H_k = 0\n",
    "                    loss_B = 0\n",
    "                    loss_total = 0\n",
    "                    \n",
    "                    loss_f = F_norm(X_Out_real*mask,X*mask)\n",
    "                    X_Out_real[mask == 1] = X[mask == 1]\n",
    "                        \n",
    "                    loss_A = gamma*torch.norm(A_hat[:,1:,:]-A_hat[:,:-1,:],1)\n",
    "                    loss_B = gamma*torch.norm(B_hat[:,:,1:]-B_hat[:,:,:-1],1)\n",
    "                    H_k = params[5]\n",
    "                    loss_H_k = gamma*torch.norm(H_k[1:,:]-H_k[:-1,:],1)\n",
    "                    \n",
    "                    optimizier.zero_grad()\n",
    "                    loss_total = loss_f + loss_A + loss_H_k + loss_B\n",
    "                    loss_total.backward(retain_graph=False)\n",
    "                    optimizier.step()\n",
    "                \n",
    "                    if (iter+1) % 250 == 0:\n",
    "                        img = X_Out_real.permute(2, 0, 1)\n",
    "                        gt = truth.permute(2,0,1)\n",
    "                        psnr = torch_psnr(img, gt)\n",
    "                        s = \"data:\" + cur_data + \"sr:\" + cur_sr + \"r:\" + str(r) + \",gamma:\" + str(gamma) + \",iter:\" + str(iter) + \",psnr:\" + str(psnr.item()) + '\\n'\n",
    "                        print(s)\n",
    "                        if psnr.item() >= base[cur]:\n",
    "                            scio.savemat(folder_path + str(iter) + \"_\" + str(psnr.item()) + \"_\" + cur_data + \"_result.mat\", {cur_data + '_result':X_Out_real.cpu().detach().numpy()})\n",
    "    cur = -1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagefusion-LRRNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf238e08655d45f0c3a7a640f429c7f53c0416161ffc99a1847e8e569afb9869"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
