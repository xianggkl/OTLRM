{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import forward\n",
    "import torch\n",
    "from torch import nn, optim \n",
    "from torch.autograd import Variable \n",
    "import os \n",
    "from utils import * \n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import numpy as np \n",
    "import scipy.io as scio\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io\n",
    "import math\n",
    "import time\n",
    "from math import exp\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para turn\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.empty_cache()\n",
    "#Case1: 0.2 G\n",
    "#Case2: 0.3 G\n",
    "case_folder = ['Case1']\n",
    "data = ['scene10']\n",
    "base = [30]\n",
    "\n",
    "# tune for better performance\n",
    "shrink = [26]\n",
    "c_all = [6e-4]\n",
    "max_iter = 1500\n",
    "lr_real = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for calculating psnr and ssim\n",
    "def torch_psnr(img, ref):  # input [28,256,256]\n",
    "    img = (img*256).round()\n",
    "    ref = (ref*256).round()\n",
    "    nC = img.shape[0]\n",
    "    psnr = 0\n",
    "    for i in range(nC):\n",
    "        mse = torch.mean((img[i, :, :] - ref[i, :, :]) ** 2)\n",
    "        psnr += 10 * torch.log10((255*255)/mse)\n",
    "    return psnr / nC\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
    "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "def ssim(img1, img2, window_size=11, size_average=True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "\n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "\n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
    "\n",
    "def torch_ssim(img, ref):  # input [28,256,256]\n",
    "    return ssim(torch.unsqueeze(img, 0), torch.unsqueeze(ref, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diagonal_S_1(nn.Module):\n",
    "    def __init__(self, n1,n2,n3):\n",
    "        super(diagonal_S_1, self).__init__()\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "        self.n3 = n3\n",
    "    \n",
    "    def forward(self, s):\n",
    "        tensor = torch.zeros(self.n3, self.n1, self.n2).cuda()\n",
    "        for i in range(self.n3):\n",
    "            tensor[i] = torch.diag(s[i])\n",
    "        return tensor\n",
    "\n",
    "class OTLinear_new(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.n_dim = shape\n",
    "        self.num_householders = shape\n",
    "        self.u = nn.Parameter(torch.randn(self.num_householders, self.n_dim))\n",
    "        self.I = nn.Parameter(torch.eye(self.n_dim, self.n_dim).unsqueeze(0))\n",
    "        self.I.requires_grad = False\n",
    "    \n",
    "    def get_weight(self, ):\n",
    "        u = F.normalize(self.u, dim=1)\n",
    "        w = self.I - 2 * u.unsqueeze(-1) @ u.unsqueeze(1)\n",
    "        w = torch.chain_matmul(*[x.squeeze(0) for x in w.chunk(self.num_householders, dim=0)])\n",
    "        return w\n",
    "        \n",
    "    def forward(self):\n",
    "        return self.get_weight()\n",
    "    \n",
    "class orth_linear(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.n_dim = shape\n",
    "        self.num_householders = shape\n",
    "        self.u = nn.Parameter(torch.randn(self.num_householders, self.n_dim))\n",
    "        self.I = nn.Parameter(torch.eye(self.n_dim, self.n_dim).unsqueeze(0))\n",
    "        self.I.requires_grad = False\n",
    "\n",
    "    def get_weight(self, ):\n",
    "        u = F.normalize(self.u, dim=1)\n",
    "        w = self.I - 2 * u.unsqueeze(-1) @ u.unsqueeze(1)\n",
    "        w = torch.chain_matmul(*[x.squeeze(0) for x in w.chunk(self.num_householders, dim=0)])\n",
    "        return w\n",
    "    \n",
    "    def forward(self, input):\n",
    "        weight = self.get_weight()\n",
    "        return torch.nn.functional.linear(input, weight)\n",
    "\n",
    "\n",
    "class SVD_net(nn.Module): \n",
    "    def __init__(self,n_1,n_2,n_3,r,shape):\n",
    "        super(SVD_net, self).__init__()\n",
    "        # shrink = 25\n",
    "        self.shape = shape\n",
    "        self.A = nn.Parameter(torch.Tensor(n_1,r,n_3))\n",
    "        self.s = nn.Parameter(torch.Tensor(r,n_3))\n",
    "        self.B = nn.Parameter(torch.Tensor(n_2,r,n_3))\n",
    "        \n",
    "        self.net_t = nn.Sequential(\n",
    "            permute_change(1,2,0),\n",
    "            orth_linear(n_3),\n",
    "            nn.Linear(n_3, n_3, bias=False)\n",
    "        ) \n",
    "        self.reset_parameters()\n",
    "        \n",
    "        self.netA = nn.Sequential(\n",
    "            orth_linear(n_3),\n",
    "            permute_change(2,0,1)\n",
    "        )\n",
    "        self.netB = nn.Sequential(\n",
    "            orth_linear(n_3),\n",
    "            permute_change(2,0,1)\n",
    "        )\n",
    "        \n",
    "        self.diagnet = diagonal_S_1(r, r, n_3)\n",
    "        self.adaptive_thres_net = nn.Sequential(\n",
    "            nn.Linear(r,r,bias = False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(r,r,bias = False)\n",
    "        )\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.A.size(2))\n",
    "        self.A.data.uniform_(-stdv, stdv)\n",
    "        self.B.data.uniform_(-stdv, stdv)\n",
    "        self.s.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self):\n",
    "        # print(self.nets(self.s).shape)\n",
    "        A_hat = self.netA(self.A)\n",
    "        B_hat_T = (self.netB(self.B)).permute(0,2,1)\n",
    "        x = torch.matmul(torch.matmul(A_hat,self.diagnet(self.adaptive_thres_net( (self.s).t() ))), B_hat_T)\n",
    "        return self.net_t(x), A_hat, B_hat_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 380304\n",
      "r:26,gamma:0.0006,iter:249,psnr:tensor(27.5629, device='cuda:1', grad_fn=<DivBackward0>)\n",
      "r:26,gamma:0.0006,iter:499,psnr:tensor(28.8396, device='cuda:1', grad_fn=<DivBackward0>)\n",
      "r:26,gamma:0.0006,iter:749,psnr:tensor(29.8096, device='cuda:1', grad_fn=<DivBackward0>)\n",
      "data:scene10,Case:Case1,r:26,gamma:0.0006,iter:749,psnr:29.809642791748047\n",
      "\n",
      "r:26,gamma:0.0006,iter:999,psnr:tensor(30.4591, device='cuda:1', grad_fn=<DivBackward0>)\n",
      "data:scene10,Case:Case1,r:26,gamma:0.0006,iter:999,psnr:30.4591121673584\n",
      "\n",
      "r:26,gamma:0.0006,iter:1249,psnr:tensor(30.6035, device='cuda:1', grad_fn=<DivBackward0>)\n",
      "data:scene10,Case:Case1,r:26,gamma:0.0006,iter:1249,psnr:30.603479385375977\n",
      "\n",
      "r:26,gamma:0.0006,iter:1499,psnr:tensor(30.5731, device='cuda:1', grad_fn=<DivBackward0>)\n",
      "data:scene10,Case:Case1,r:26,gamma:0.0006,iter:1499,psnr:30.573068618774414\n",
      "\n",
      "14.71748948097229\n"
     ]
    }
   ],
   "source": [
    "cur = -1\n",
    "for cur_data in data:\n",
    "    folder_path = \"./results/denoising/ours/kaist/\" + cur_data + \"/\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "        \n",
    "    for cur_case in case_folder:\n",
    "        cur = cur + 1\n",
    "        \n",
    "        file_name = './data/denoising/kaist/' + cur_data + '/' + cur_case + '/' + cur_data + '_noise.mat'\n",
    "        mat = scipy.io.loadmat(file_name)\n",
    "        X_np = mat[\"Nmsi\"]\n",
    "        X = torch.from_numpy(X_np).type(dtype).cuda()\n",
    "\n",
    "        truth = torch.from_numpy(mat[\"Omsi\"]).type(dtype).cuda()\n",
    "        \n",
    "        folder_path = \"./results/denoising/ours/kaist/\" + cur_data + \"/\" + cur_case + \"/\"\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.mkdir(folder_path)\n",
    "            \n",
    "        for r in shrink:\n",
    "            folder_path = \"./results/denoising/ours/kaist/\" + cur_data + \"/\" + cur_case + \"/\" + \"r\" + str(r) + \"/\"\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.mkdir(folder_path)\n",
    "            \n",
    "            for gamma in c_all:\n",
    "                \n",
    "                folder_path = \"./results/denoising/ours/kaist/\" + cur_data + \"/\" + cur_case + \"/\" + \"r\" + str(r) + \"/\" + \"gamma\" + str(gamma) + \"/\"\n",
    "                if not os.path.exists(folder_path):\n",
    "                    os.mkdir(folder_path)\n",
    "                \n",
    "                model = SVD_net(256,256,28, r,256).type(dtype)\n",
    "                mask = torch.ones(X.shape).type(dtype)\n",
    "                mask[X == 0] = 0\n",
    "                X[mask == 0] = 0\n",
    "                \n",
    "                params = []\n",
    "                params += [x for x in model.parameters()]\n",
    "                s = sum([np.prod(list(p.size())) for p in params]);\n",
    "                print('Number of params: %d' % s)\n",
    "                optimizier = optim.Adam(params, lr=lr_real, weight_decay=10e-6)\n",
    "                \n",
    "                t0 = time.time()\n",
    "                # show = [0,5,9]\n",
    "                for iter in range(max_iter):\n",
    "                    X_Out_real, A_hat, B_hat = model()\n",
    "                    \n",
    "                    loss_f = 0\n",
    "                    loss_A = 0\n",
    "                    loss_H_k = 0\n",
    "                    loss_B = 0\n",
    "                    loss_total = 0\n",
    "                    \n",
    "                    loss_f = 10e-6*torch.norm(X_Out_real*mask-X*mask,1)\n",
    "                    # A_hat = params[0]\n",
    "                    loss_A = gamma*torch.norm(A_hat[:,1:,:]-A_hat[:,:-1,:],1)\n",
    "                    # B_hat = params[2]\n",
    "                    loss_B = gamma*torch.norm(B_hat[:,:,1:]-B_hat[:,:,:-1],1)\n",
    "                    H_k = params[5]\n",
    "                    # print(H_k.shape)\n",
    "                    loss_H_k = gamma*torch.norm(H_k[1:,:]-H_k[:-1,:],1)\n",
    "                    \n",
    "                    optimizier.zero_grad()\n",
    "                    loss_total = loss_f + loss_H_k + loss_A + loss_B\n",
    "                    loss_total.backward(retain_graph=False)\n",
    "                    optimizier.step()\n",
    "                \n",
    "                    if (iter+1) % 250 == 0:\n",
    "                        img = X_Out_real.permute(2, 0, 1)\n",
    "                        gt = truth.permute(2,0,1)\n",
    "                        psnr = torch_psnr(img, gt)\n",
    "                        print(\"r:\" + str(r) + \",gamma:\" + str(gamma) + \",iter:\" + str(iter) + \",psnr:\" + str(psnr))\n",
    "\n",
    "                        if psnr.item() >= base[cur]:\n",
    "                            scio.savemat(folder_path + str(iter) + \"_\" + str(psnr.item()) + \"_\" + cur_data + \"_result.mat\", {cur_data + '_result':X_Out_real.cpu().detach().numpy()})\n",
    "                        if psnr.item() >= base[cur] - 1:\n",
    "                            s = \"data:\" + cur_data + \",Case:\" + cur_case + \",r:\" + str(r) + \",gamma:\" + str(gamma) + \",iter:\" + str(iter) + \",psnr:\" + str(psnr.item()) + '\\n'\n",
    "                            with open('./results/denoising/ours/kaist/'+ cur_data + '/' + cur_case + \"/\" + '/psnr.txt', 'a', encoding='utf-8') as f:\n",
    "                                f.write(s)\n",
    "                            print(s)\n",
    "                t1 = time.time()\n",
    "                print(t1-t0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagefusion-LRRNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf238e08655d45f0c3a7a640f429c7f53c0416161ffc99a1847e8e569afb9869"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
