{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import forward\n",
    "import torch\n",
    "from torch import nn, optim \n",
    "from torch.autograd import Variable \n",
    "import os \n",
    "from utils import * \n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import numpy as np \n",
    "import scipy.io as scio\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io\n",
    "import math\n",
    "import time\n",
    "from math import exp\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# tune for best performance\n",
    "shrink = [20]\n",
    "c_all = [1e-6]\n",
    "\n",
    "max_iter = 12000\n",
    "lr_real = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for calculating psnr and ssim\n",
    "def torch_psnr(img, ref):  # input [28,256,256]\n",
    "    img = (img*256).round()\n",
    "    ref = (ref*256).round()\n",
    "    nC = img.shape[0]\n",
    "    psnr = 0\n",
    "    for i in range(nC):\n",
    "        mse = torch.mean((img[i, :, :] - ref[i, :, :]) ** 2)\n",
    "        psnr += 10 * torch.log10((255*255)/mse)\n",
    "    return psnr / nC\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
    "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "def ssim(img1, img2, window_size=11, size_average=True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "\n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "\n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
    "\n",
    "def torch_ssim(img, ref):  # input [28,256,256]\n",
    "    return ssim(torch.unsqueeze(img, 0), torch.unsqueeze(ref, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class diagonal_S_1(nn.Module):\n",
    "    def __init__(self, n1,n2,n3):\n",
    "        super(diagonal_S_1, self).__init__()\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "        self.n3 = n3\n",
    "    \n",
    "    def forward(self, s):\n",
    "        tensor = torch.zeros(self.n3, self.n1, self.n2).cuda()\n",
    "        for i in range(self.n3):\n",
    "            tensor[i] = torch.diag(s[i])\n",
    "        return tensor\n",
    "\n",
    "class OTLinear_new(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.n_dim = shape\n",
    "        self.num_householders = shape\n",
    "        self.u = nn.Parameter(torch.randn(self.num_householders, self.n_dim))\n",
    "        self.I = nn.Parameter(torch.eye(self.n_dim, self.n_dim).unsqueeze(0))\n",
    "        self.I.requires_grad = False\n",
    "    \n",
    "    def get_weight(self, ):\n",
    "        u = F.normalize(self.u, dim=1)\n",
    "        w = self.I - 2 * u.unsqueeze(-1) @ u.unsqueeze(1)\n",
    "        w = torch.chain_matmul(*[x.squeeze(0) for x in w.chunk(self.num_householders, dim=0)])\n",
    "        return w\n",
    "        \n",
    "    def forward(self):\n",
    "        return self.get_weight()\n",
    "    \n",
    "class orth_linear(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.n_dim = shape\n",
    "        self.num_householders = shape\n",
    "        self.u = nn.Parameter(torch.randn(self.num_householders, self.n_dim))\n",
    "        self.I = nn.Parameter(torch.eye(self.n_dim, self.n_dim).unsqueeze(0))\n",
    "        self.I.requires_grad = False\n",
    "\n",
    "    def get_weight(self, ):\n",
    "        u = F.normalize(self.u, dim=1)\n",
    "        w = self.I - 2 * u.unsqueeze(-1) @ u.unsqueeze(1)\n",
    "        w = torch.chain_matmul(*[x.squeeze(0) for x in w.chunk(self.num_householders, dim=0)])\n",
    "        return w\n",
    "    \n",
    "    def forward(self, input):\n",
    "        weight = self.get_weight()\n",
    "        return torch.nn.functional.linear(input, weight)\n",
    "        # h, w, _ = input.shape\n",
    "        # input = input.view(h * w, self.n_dim)\n",
    "        # return (torch.matmul(input, weight)).view(h,w,self.n_dim)\n",
    "\n",
    "\n",
    "class SVD_net(nn.Module): \n",
    "    def __init__(self,n_1,n_2,n_3,shrink,shape):\n",
    "        super(SVD_net, self).__init__()\n",
    "        # shrink = 25\n",
    "        self.shape = shape\n",
    "        self.A = nn.Parameter(torch.Tensor(n_1,n_2//shrink,n_3))\n",
    "        self.s = nn.Parameter(torch.Tensor(n_2//shrink,n_3))\n",
    "        self.B = nn.Parameter(torch.Tensor(n_2,n_2//shrink,n_3))\n",
    "        \n",
    "        self.net_t = nn.Sequential(\n",
    "            permute_change(1,2,0),\n",
    "            orth_linear(n_3),\n",
    "            nn.Linear(n_3, n_3, bias=False)\n",
    "        ) \n",
    "        self.reset_parameters()\n",
    "        \n",
    "        self.netA = nn.Sequential(\n",
    "            orth_linear(n_3),\n",
    "            permute_change(2,0,1)\n",
    "        )\n",
    "        self.netB = nn.Sequential(\n",
    "            orth_linear(n_3),\n",
    "            permute_change(2,0,1)\n",
    "        )\n",
    "        \n",
    "        self.diagnet = diagonal_S_1(n_2//shrink, n_2//shrink, n_3)\n",
    "        self.adaptive_thres_net = nn.Sequential(\n",
    "            nn.Linear(n_2//shrink,n_2//shrink,bias = False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(n_2//shrink,n_2//shrink,bias = False)\n",
    "        )\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.A.size(2))\n",
    "        self.A.data.uniform_(-stdv, stdv)\n",
    "        self.B.data.uniform_(-stdv, stdv)\n",
    "        self.s.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self):\n",
    "        A_hat = self.netA(self.A)\n",
    "        B_hat_T = (self.netB(self.B)).permute(0,2,1)\n",
    "        x = torch.matmul(torch.matmul(A_hat,self.diagnet(self.adaptive_thres_net( (self.s).t() ))), B_hat_T)\n",
    "        return self.net_t(x), A_hat, B_hat_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 178144\n",
      "r:20,gamma:1e-06,iter:999,psnr:38.76161193847656\n",
      "\n",
      "r:20,gamma:1e-06,iter:1999,psnr:42.30829620361328\n",
      "\n",
      "r:20,gamma:1e-06,iter:2999,psnr:43.29865264892578\n",
      "\n",
      "r:20,gamma:1e-06,iter:3999,psnr:43.58987045288086\n",
      "\n",
      "r:20,gamma:1e-06,iter:4999,psnr:43.684505462646484\n",
      "\n",
      "r:20,gamma:1e-06,iter:5999,psnr:43.72355270385742\n",
      "\n",
      "r:20,gamma:1e-06,iter:6999,psnr:43.774356842041016\n",
      "\n",
      "r:20,gamma:1e-06,iter:7999,psnr:43.83332824707031\n",
      "\n",
      "r:20,gamma:1e-06,iter:8999,psnr:43.87248611450195\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_339345/1415516273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mX_Out_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mout_shift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mout_shift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/miniconda3/envs/imagefusion-LRRNet/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_339345/223597067.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mA_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mB_hat_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_thres_net\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_hat_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_hat_T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/programs/miniconda3/envs/imagefusion-LRRNet/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_339345/223597067.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "truth_np = scipy.io.loadmat(\"./data/snapshot/truth/scene04.mat\")\n",
    "truth = torch.from_numpy(truth_np['img']).cuda()\n",
    "\n",
    "# load measurement and 3d-shift-mask\n",
    "file_name = \"./data/snapshot/measurement_mask/scene04_mask_And_meas.mat\"\n",
    "mat = scipy.io.loadmat(file_name)\n",
    "X_np = mat[\"Nhsi\"]\n",
    "X = torch.from_numpy(X_np).type(dtype).cuda() # measurement\n",
    "shift_3d_mask_np = mat[\"mask\"]\n",
    "shift_3d_mask = torch.from_numpy(shift_3d_mask_np).type(dtype).cuda() # 3d-shift-mask\n",
    "\n",
    "for r in shrink:\n",
    "    folder_path = \"./results/snapshot/ours/scene04/\" + \"r\" + str(r) + \"/\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "    \n",
    "    for gamma in c_all:\n",
    "        F_norm = nn.MSELoss()\n",
    "        \n",
    "        model = SVD_net(256,256,28, r,256).type(dtype)\n",
    "        \n",
    "        params = []\n",
    "        params += [x for x in model.parameters()]\n",
    "        \n",
    "        s = sum([np.prod(list(p.size())) for p in params]);\n",
    "        print('Number of params: %d' % s)\n",
    "        optimizier = optim.Adam(params, lr=lr_real, weight_decay=10e-8)\n",
    "        \n",
    "        t0 = time.time()\n",
    "        for iter in range(max_iter):\n",
    "            X_Out_real, A_hat, B_hat = model()\n",
    "            out_shift = np.zeros((256, 256 + 2 * (28 - 1), 28))\n",
    "            out_shift = torch.from_numpy(out_shift).type(dtype).cuda()\n",
    "            for i in range(28):\n",
    "                out_shift[:,i*2:i*2+256,i]=X_Out_real[:,:,i]\n",
    "\n",
    "            loss_f = 0\n",
    "            loss_A = 0\n",
    "            loss_H_k = 0\n",
    "            loss_B = 0\n",
    "            loss_total = 0\n",
    "            \n",
    "            loss_f = F_norm(torch.sum(out_shift*shift_3d_mask,dim = 2),X)\n",
    "            loss_A = gamma*torch.norm(A_hat[:,1:,:]-A_hat[:,:-1,:],1)\n",
    "            loss_B = gamma*torch.norm(B_hat[:,:,1:]-B_hat[:,:,:-1],1)\n",
    "            H_k = params[5]\n",
    "            loss_H_k = gamma*torch.norm(H_k[1:,:]-H_k[:-1,:],1)\n",
    "            \n",
    "            optimizier.zero_grad()\n",
    "            loss_total = loss_f + loss_A + loss_H_k + loss_B\n",
    "            loss_total.backward(retain_graph=False)\n",
    "            optimizier.step()\n",
    "        \n",
    "            if (iter+1) % 1000 == 0:\n",
    "                folder_path = \"./results/snapshot/ours/scene04/\" + \"r\" + str(r) + \"/\" + \"gamma\" + str(gamma) + \"/\"\n",
    "                if not os.path.exists(folder_path):\n",
    "                    os.mkdir(folder_path)\n",
    "                \n",
    "                img = X_Out_real.permute(2, 0, 1)\n",
    "                gt = truth.permute(2,0,1)\n",
    "                psnr = torch_psnr(img, gt)\n",
    "                if psnr.item() >= 44.0:\n",
    "                    scio.savemat(folder_path + str(iter) + \"_\" + str(psnr.item()) + \"_scene04_result.mat\", {'scene04_result':X_Out_real.cpu().detach().numpy()})\n",
    "                s = \"r:\" + str(r) + \",gamma:\" + str(gamma) + \",iter:\" + str(iter) + \",psnr:\" + str(psnr.item()) + '\\n'\n",
    "                with open('./results/snapshot/ours/scene04/psnr.txt', 'a', encoding='utf-8') as f:\n",
    "                    f.write(s)\n",
    "                print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagefusion-LRRNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf238e08655d45f0c3a7a640f429c7f53c0416161ffc99a1847e8e569afb9869"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
